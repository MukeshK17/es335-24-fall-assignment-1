{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (54, 500, 3)\n",
      "Testing data shape:  (126, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "# Available Models\n",
    "groq_models = {\n",
    "    \"llama3-70b\": \"llama3-70b-8192\",\n",
    "    \"gemma-7b\": \"gemma-7b-it\",\n",
    "    \"llama3.1-70b\":\"llama-3.1-70b-versatile\",\n",
    "    \"llama3-8b\":\"llama3-8b-8192\"\n",
    "    }\n",
    "model = groq_models[\"llama3-70b\"]\n",
    "\n",
    "# Constants\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "green = \"\\x1b[32;40m\"\n",
    "red =   \"\\x1b[31;40m\"\n",
    "reset = \"\\x1b[0m\"       # color reset\n",
    "time = 10\n",
    "offset = 100\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "folders = list(classes.keys())\n",
    "\n",
    "combined_dir = os.path.join(\"./HAR/Combined\")\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 100\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.7,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n",
    "\n",
    "X_examples = []\n",
    "y_examples = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] not in y_examples:\n",
    "        X_examples.append(X_train[i])\n",
    "        y_examples.append(y_train[i])\n",
    "\n",
    "zero_shot_prompt = lambda data:f\"\"\"\n",
    "* Your task is to classify the given 3-axis accelerometer data into one of the following activity labels by analyzing the previously given training data.\n",
    "1) WALKING\n",
    "2) SITTING\n",
    "3) STANDING\n",
    "4) WALKING_UPSTAIRS\n",
    "5) WALKING_DOWNSTAIRS\n",
    "6) LAYING\n",
    "* Accelerometer data represents movement in different directions.\n",
    "- The x-axis represents forward and backward movement.\n",
    "- The y-axis represents lateral (side-to-side) movement.\n",
    "- The z-axis represents vertical movement.\n",
    "* Only output the identified label and nothing else.\n",
    "* Do not provide any explanation or analysis.\n",
    "Acceleration Data:\n",
    "{data}\n",
    "\"\"\"\n",
    "\n",
    "examples = \"\\n\".join([f\"EXAMPLE {i} DATA :\\n{pd.DataFrame(X_examples[i],columns=['accX','accY','accZ'])}\\nEXAMPLE {i} LABEL : {folders[y_examples[i]-1]}\" for i in range(len(X_examples))])\n",
    "\n",
    "few_shot_prompt = lambda data:f\"\"\"\n",
    "* You are HAR tool.\n",
    "* Your task is to analyze the provided labeled 3 axis accelerometer data and learn the patterns associated with the label in order to identify unlabeled data.\n",
    "* Accelerometer data represents movement in different directions\n",
    "- The x-axis represents forward and backward movement.\n",
    "- The y-axis represents lateral (side-to-side) movement.\n",
    "- The z-axis represents vertical movement.\n",
    "* Only give output in one word and do not provide any explanation.\n",
    "{examples}\n",
    "\n",
    "TEST DATA: {data}\n",
    "LABEL for TEST DATA: ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-70b-8192: Test case #125 Output: \u001b[31;40mSTANDING           \u001b[0mActual: SITTING              Correct: 33\n",
      "Model:              llama3-70b-8192\n",
      "Total Test Cases:   126\n",
      "Correct Prediction: 33\n",
      "Accuracy:           0.26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_shot_correct_count = 0\n",
    "\n",
    "llm = ChatGroq(model=model, api_key=GROQ_API_KEY, temperature=0)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "\n",
    "    query = zero_shot_prompt(pd.DataFrame(X_test[i],columns=['accX','accY','accZ']))\n",
    "    ans = llm.invoke(query).content\n",
    "\n",
    "    if(ans==folders[y_test[i]-1]):\n",
    "        zero_shot_correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "\n",
    "    print(f\"\\r{model:<15}: Test case #{i:<3} Output: {color}{ans:<18} {reset}Actual: {folders[y_test[i]-1]:<20} Correct: {zero_shot_correct_count}\",end=\"\")\n",
    "\n",
    "print()\n",
    "print(f\"\"\"\n",
    "Model:              {model}\n",
    "Total Test Cases:   {len(X_test)}\n",
    "Correct Predictions:{zero_shot_correct_count}\n",
    "Accuracy:           {zero_shot_correct_count/(len(X_test)):.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-70b-8192: Test case #125 Output: \u001b[32;40mSITTING            \u001b[0mActual: SITTING              Correct:53\n",
      "\n",
      "Model:               llama3-70b-8192\n",
      "Total Test Cases:    126\n",
      "Correct Predictions: 53\n",
      "Accuracy:            0.42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot_correct_count = 0\n",
    "\n",
    "llm = ChatGroq(model=model, api_key=GROQ_API_KEY, temperature=0)\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "\n",
    "    query = few_shot_prompt(pd.DataFrame(X_test[i],columns=['accX','accY','accZ']))\n",
    "    ans = llm.invoke(query).content\n",
    "\n",
    "    if(ans==folders[y_test[i]-1]):\n",
    "        few_shot_correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "\n",
    "    print(f\"\\r{model:<15}: Test case #{i:<3} Output: {color}{ans:<18} {reset}Actual: {folders[y_test[i]-1]:<20} Correct:{few_shot_correct_count}\",end=\"\")\n",
    "\n",
    "print()\n",
    "print(f\"\"\"\n",
    "Model:               {model}\n",
    "Total Test Cases:    {len(X_test)}\n",
    "Correct Predictions: {few_shot_correct_count}\n",
    "Accuracy:            {few_shot_correct_count/len(X_test):.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Few-shot and Zero-shot\n",
    "\n",
    "Although the accuracy depends on the choices of examples and test cases provided, Few-shot always gives more accuracy compared to Zero-shot.\n",
    "\n",
    "The reason of this difference between the accuracies lie between the fact that we provide some examples of all the possible  classification allowing the LLM to refer to examples and compare the test data, whereas in Zero-shot this was not possible, as LLMs are not trained on large numerical data for HAR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of Zero-shot and Few-Shot in HAR\n",
    "\n",
    "In Zero-shot learning as the LLM has no data to learn from, it is more prone to errors, but is comparatively faster than the Few-shot, as Few-shot has to first learn from the examples provided and then analyze the input.\n",
    "\n",
    "In Few-shot learning, the LLM has to be provided correct examples which are sometimes unknown or are biased. This biasness in the examples can make the Few-shot learning more biased, giving less accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with New Activity\n",
    "\n",
    "We have taken \"JOGGING\" as new activity. We downloaded the data from https://www.cis.fordham.edu/wisdm/dataset.php as raw text.\n",
    "Then we took sample data from user id 33 and pre-processed the raw data to remove all the other activities and user ids.\n",
    "\n",
    "The sample data file is saved as `jogging.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WALKING\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./jogging.csv\",sep=\",\",header=0)\n",
    "X_new_test = df[time:time+offset]\n",
    "\n",
    "query = zero_shot_prompt(X_new_test)\n",
    "\n",
    "ans = llm.invoke(query).content\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that as the LLM was not provided examples associated with the JOGGING activity, it is unable to identify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Few Shot with Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3-70b-8192: Test case #125 Output: \u001b[31;40mWALKING            \u001b[0mActual: STANDING             Correct:26\n",
      "\n",
      "Model:               llama3-70b-8192\n",
      "Total Test Cases:    126\n",
      "Correct Predictions: 26\n",
      "Accuracy:            0.21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_min = np.min(X_test)\n",
    "x_max = np.max(X_test)\n",
    "y_min = np.min(y_test)\n",
    "y_max = np.max(y_test)\n",
    "\n",
    "X_random = (x_max-x_min)*np.random.random(X_test.shape) + x_min\n",
    "y_random = np.random.randint(y_min,y_max+1,len(X_test))\n",
    "\n",
    "rand_correct_count = 0\n",
    "\n",
    "llm = ChatGroq(model=model, api_key=GROQ_API_KEY, temperature=0)\n",
    "\n",
    "for i in range(len(X_random)):\n",
    "\n",
    "    query = few_shot_prompt(X_random[i])\n",
    "    ans = llm.invoke(query).content\n",
    "\n",
    "    if(ans==folders[y_random[i]-1]):\n",
    "        rand_correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "\n",
    "    print(f\"\\r{model:<15}: Test case #{i:<3} Output: {color}{ans:<18} {reset}Actual: {folders[y_random[i]-1]:<20} Correct:{rand_correct_count}\",end=\"\")\n",
    "    \n",
    "print()\n",
    "print(f\"\"\"\n",
    "Model:               {model}\n",
    "Total Test Cases:    {len(X_random)}\n",
    "Correct Predictions: {rand_correct_count}\n",
    "Accuracy:            {rand_correct_count/len(X_random):.2f}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
