{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq.chat_models import ChatGroq\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Available Models\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}\n",
    "model = groq_models[\"llama3-70b\"]\n",
    "\n",
    "# Constants\n",
    "green = \"\\x1b[38;2;152;251;152m\"\n",
    "red = \"\\x1b[38;2;255;0;0m\"\n",
    "reset = \"\\x1b[0m\"\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"./HAR/Combined\")\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n",
    "\n",
    "categories = list(classes.keys())\n",
    "\n",
    "# train prompt template\n",
    "train_prompt = lambda data,category: f\"\"\"\n",
    "You do not need to output anything for this query.\n",
    "Example data for \"{category}\":\n",
    "{data}\n",
    "\"\"\"\n",
    "\n",
    "# test prompt template\n",
    "test_prompt = lambda data: f\"\"\"\n",
    "You will be provided 3-axis accelerometer data from one of the following activities:\n",
    "    1) WALKING\n",
    "    2) LAYING\n",
    "    3) WALKING_UPSTAIRS\n",
    "    4) WALKING_DOWNSTAIRS\n",
    "    5) SITTING\n",
    "    6) STANDING\n",
    "You have to ouput only the name of the predicted activity and nothing else.\n",
    "DATA:\n",
    "{data}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "1) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "2) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "3) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "4) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "5) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "6) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "7) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "8) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "9) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "10) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "11) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "12) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "13) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "14) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "15) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "16) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "17) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "18) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "19) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "20) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "21) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "22) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "23) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING_UPSTAIRS\u001b[0m\n",
      "24) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "25) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "26) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "27) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "28) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "29) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "30) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "31) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "32) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "33) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING_UPSTAIRS\u001b[0m\n",
      "34) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "35) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "36) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "37) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "38) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "39) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "40) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "41) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "42) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "43) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "44) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "45) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "46) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "47) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "48) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "49) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "50) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "51) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "52) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "53) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "\n",
      "Total: 54\n",
      "Correct: 11\n",
      "Accuracy: 0.2037037037037037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=model, api_key=GROQ_API_KEY, temperature=0)\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    query = test_prompt(X_test[i])\n",
    "    ans = llm.invoke(query).content\n",
    "    if(ans==categories[y_test[i]-1]):\n",
    "        correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "    print(f\"{i}) Actual: {categories[y_test[i]-1]}\\n{color}Predicted: {ans}{reset}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Total: {len(X_test)}\n",
    "Correct: {correct_count}\n",
    "Accuracy: {correct_count/len(X_test)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shots (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to learn from the examples. Please provide the 3-axis accelerometer data for each of the activities (WALKING, LAYING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING). I'll learn from these examples and prepare to be tested against the test dataset.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=model, api_key=GROQ_API_KEY, temperature=0)\n",
    "\n",
    "print(llm.invoke(\"\"\"\n",
    "You will be provided examples for 3-axis accelerometer data from one of the following activities:\n",
    "    1) WALKING\n",
    "    2) LAYING\n",
    "    3) WALKING_UPSTAIRS\n",
    "    4) WALKING_DOWNSTAIRS\n",
    "    5) SITTING\n",
    "    6) STANDING\n",
    "You have to learn from these examples and then you will be tested against test dataset.\n",
    "You do not need to output anything for this query.\n",
    "\"\"\").content)\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    query = train_prompt(X_train[i],categories[y_train[i]-1])\n",
    "    response = llm.invoke(query)\n",
    "    #print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shots (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "1) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "2) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "3) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "4) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "5) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "6) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "7) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "8) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "9) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "10) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "11) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "12) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "13) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "14) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "15) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "16) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "17) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "18) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "19) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "20) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "21) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "22) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "23) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING_UPSTAIRS\u001b[0m\n",
      "24) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "25) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "26) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "27) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "28) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "29) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "30) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "31) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "32) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "33) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING_UPSTAIRS\u001b[0m\n",
      "34) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "35) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "36) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "37) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "38) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "39) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "40) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "41) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "42) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "43) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "44) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "45) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "46) Actual: STANDING\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "47) Actual: WALKING\n",
      "\u001b[38;2;152;251;152mPredicted: WALKING\u001b[0m\n",
      "48) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "49) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "50) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "51) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "52) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: WALKING\u001b[0m\n",
      "53) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "Total: 54\n",
      "Correct: 11\n",
      "Accuracy: 0.2037037037037037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    query = test_prompt(X_test[i])\n",
    "    ans = llm.invoke(query).content\n",
    "    if(ans==categories[y_test[i]-1]):\n",
    "        correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "    print(f\"{i}) Actual: {categories[y_test[i]-1]}\\n{color}Predicted: {ans}{reset}\")\n",
    "\n",
    "print(f\"\"\"Total: {len(X_test)}\n",
    "Correct: {correct_count}\n",
    "Accuracy: {correct_count/len(X_test)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "1) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "2) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "3) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "4) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "5) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "6) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "7) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "8) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "9) Actual: WALKING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "10) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "11) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "12) Actual: WALKING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "13) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "14) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "15) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "16) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "17) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "18) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "19) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "20) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "21) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "22) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "23) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "24) Actual: WALKING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "25) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "26) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "27) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "28) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "29) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "30) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "31) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "32) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "33) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "34) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "35) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "36) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "37) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "38) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "39) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "40) Actual: STANDING\n",
      "\u001b[38;2;152;251;152mPredicted: STANDING\u001b[0m\n",
      "41) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "42) Actual: WALKING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "43) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "44) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "45) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "46) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "47) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "48) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "49) Actual: WALKING_UPSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "50) Actual: WALKING_DOWNSTAIRS\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "51) Actual: SITTING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "52) Actual: WALKING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "53) Actual: LAYING\n",
      "\u001b[38;2;255;0;0mPredicted: STANDING\u001b[0m\n",
      "Total: 54\n",
      "Correct: 10\n",
      "Accuracy: 0.18518518518518517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_min = np.min(X_test)\n",
    "x_max = np.max(X_test)\n",
    "y_min = np.min(y_test)\n",
    "y_max = np.max(y_test)\n",
    "\n",
    "X_test = (x_max-x_min)*np.random.random(len(X_test)) + x_min\n",
    "y_test = np.random.randint(y_min,y_max+1,len(X_test))\n",
    "\n",
    "correct_count = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    query = test_prompt(X_test[i])\n",
    "    ans = llm.invoke(query).content\n",
    "    if(ans==categories[y_test[i]-1]):\n",
    "        correct_count+=1\n",
    "        color = green\n",
    "    else:\n",
    "        color = red\n",
    "    print(f\"{i}) Actual: {categories[y_test[i]-1]}\\n{color}Predicted: {ans}{reset}\")\n",
    "\n",
    "print(f\"\"\"Total: {len(X_test)}\n",
    "Correct: {correct_count}\n",
    "Accuracy: {correct_count/len(X_test)}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
